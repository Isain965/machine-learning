{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tample for our projects with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First method for reading the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para leer el archivo\n",
    "with open('../datasets/hepatitis.dat', 'r') as lector:\n",
    "    lista = lector.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostFrequent(arr):\n",
    "    n = len(arr)\n",
    "    # Insert all elements in Hash.\n",
    "    Hash = dict()\n",
    "    for i in range(n):\n",
    "        if arr[i] in Hash.keys():\n",
    "            Hash[arr[i]] += 1\n",
    "        else:\n",
    "            Hash[arr[i]] = 1\n",
    "    # find the max frequency\n",
    "    max_count = 0\n",
    "    res = -1\n",
    "    for i in Hash:\n",
    "        if (max_count < Hash[i]):\n",
    "            res = i\n",
    "            max_count = Hash[i]\n",
    "    return res\n",
    "\n",
    "def obtienePromedio(arr):\n",
    "    if(len(arr) == 0):\n",
    "        return 0\n",
    "    suma = 0\n",
    "    for element in arr:\n",
    "        suma += element\n",
    "    return suma // len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 85, 18, 0, 61, 1]\n",
      "[50, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 0, 135, 42, 0, 61, 1]\n",
      "[78, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 96, 32, 0, 61, 1]\n",
      "[31, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 46, 52, 0, 80, 1]\n",
      "[34, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 200, 0, 61, 1]\n",
      "[34, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 95, 28, 0, 75, 1]\n",
      "[51, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 0, 105, 85, 0, 61, 1]\n",
      "[23, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 85, 0, 61, 1]\n",
      "[39, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 105, 48, 0, 61, 1]\n",
      "[30, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 120, 0, 61, 1]\n",
      "[39, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 78, 30, 0, 85, 1]\n",
      "[32, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 0, 59, 249, 0, 54, 1]\n",
      "[41, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 81, 60, 0, 52, 1]\n",
      "[30, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 57, 144, 0, 78, 1]\n",
      "[47, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 60, 0, 61, 1]\n",
      "[38, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 0, 72, 89, 0, 46, 1]\n",
      "[66, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 102, 53, 0, 61, 1]\n",
      "[40, 1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 62, 166, 0, 63, 1]\n",
      "[38, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 53, 42, 0, 85, 2]\n",
      "[38, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 70, 28, 0, 62, 1]\n",
      "[22, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 48, 20, 0, 64, 1]\n",
      "[27, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 133, 98, 0, 39, 1]\n",
      "[31, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 85, 20, 0, 100, 1]\n",
      "[42, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 60, 63, 0, 47, 1]\n",
      "[25, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 45, 18, 0, 70, 1]\n",
      "[27, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 95, 46, 0, 100, 1]\n",
      "[49, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 0, 85, 48, 0, 61, 1]\n",
      "[58, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 0, 175, 55, 0, 36, 1]\n",
      "[61, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 0, 78, 25, 0, 100, 1]\n",
      "[51, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 78, 58, 0, 52, 1]\n",
      "[39, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 280, 98, 0, 40, 1]\n",
      "[62, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 105, 60, 0, 61, 1]\n",
      "[41, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 81, 53, 0, 74, 1]\n",
      "[26, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 135, 29, 0, 60, 1]\n",
      "[35, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 58, 92, 0, 73, 1]\n",
      "[37, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 0, 67, 28, 0, 61, 1]\n",
      "[23, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 0, 194, 150, 0, 90, 1]\n",
      "[20, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 150, 68, 0, 61, 1]\n",
      "[42, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 85, 14, 0, 100, 1]\n",
      "[65, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 0, 180, 53, 0, 74, 2]\n",
      "[52, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 75, 55, 0, 21, 1]\n",
      "[23, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 56, 16, 0, 61, 1]\n",
      "[33, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 46, 90, 0, 60, 1]\n",
      "[56, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 71, 18, 0, 100, 1]\n",
      "[34, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 86, 0, 61, 1]\n",
      "[28, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 74, 110, 0, 61, 1]\n",
      "[37, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 0, 80, 80, 0, 61, 1]\n",
      "[28, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 191, 420, 0, 46, 1]\n",
      "[36, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 85, 44, 0, 85, 1]\n",
      "[38, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 0, 125, 65, 0, 77, 1]\n",
      "[39, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 85, 60, 0, 61, 1]\n",
      "[39, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 85, 20, 0, 61, 1]\n",
      "[44, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 110, 145, 0, 70, 1]\n",
      "[40, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 0, 85, 31, 0, 100, 1]\n",
      "[30, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 50, 78, 0, 74, 1]\n",
      "[37, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 92, 59, 0, 61, 1]\n",
      "[34, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 85, 0, 61, 1]\n",
      "[30, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 52, 38, 0, 52, 1]\n",
      "[64, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 0, 80, 38, 0, 74, 1]\n",
      "[45, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 0, 85, 75, 0, 61, 1]\n",
      "[37, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 26, 58, 0, 100, 1]\n",
      "[32, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 102, 64, 0, 90, 1]\n",
      "[32, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 0, 215, 54, 0, 29, 1]\n",
      "[36, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 0, 164, 44, 0, 41, 1]\n",
      "[49, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 103, 43, 0, 66, 1]\n",
      "[27, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 38, 0, 61, 1]\n",
      "[56, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 62, 33, 0, 61, 1]\n",
      "[57, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 105, 48, 0, 73, 1]\n",
      "[39, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 34, 15, 0, 54, 1]\n",
      "[44, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 68, 68, 0, 61, 1]\n",
      "[24, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 82, 39, 0, 61, 1]\n",
      "[34, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 0, 127, 182, 0, 61, 1]\n",
      "[51, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 76, 271, 0, 61, 1]\n",
      "[36, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 0, 105, 45, 0, 57, 1]\n",
      "[50, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 100, 100, 0, 61, 1]\n",
      "[32, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 55, 45, 0, 56, 1]\n",
      "[58, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 167, 242, 0, 61, 1]\n",
      "[34, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 30, 24, 0, 76, 1]\n",
      "[34, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 0, 72, 46, 0, 57, 1]\n",
      "[28, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 85, 31, 0, 61, 1]\n",
      "[23, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 105, 14, 0, 61, 1]\n",
      "[36, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 62, 224, 0, 100, 1]\n",
      "[30, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 100, 31, 0, 100, 1]\n",
      "[67, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 179, 69, 0, 61, 1]\n",
      "[62, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 141, 156, 0, 58, 1]\n",
      "[28, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 0, 44, 123, 0, 46, 1]\n",
      "[44, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 0, 135, 55, 0, 41, 2]\n",
      "[30, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 165, 64, 0, 61, 2]\n",
      "[38, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 118, 16, 0, 61, 2]\n",
      "[38, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 76, 18, 0, 84, 2]\n",
      "[50, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 230, 117, 0, 41, 2]\n",
      "[42, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 0, 105, 55, 0, 61, 2]\n",
      "[33, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 60, 0, 61, 2]\n",
      "[52, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 69, 0, 61, 2]\n",
      "[59, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 0, 107, 157, 0, 38, 2]\n",
      "[40, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 40, 69, 0, 67, 2]\n",
      "[30, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 147, 128, 0, 100, 2]\n",
      "[44, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 0, 114, 65, 0, 61, 2]\n",
      "[47, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 0, 84, 23, 0, 66, 2]\n",
      "[60, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 105, 40, 0, 61, 2]\n",
      "[48, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 0, 123, 157, 0, 31, 2]\n",
      "[22, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 24, 0, 61, 2]\n",
      "[27, 1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 168, 227, 0, 66, 2]\n",
      "[51, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0, 215, 269, 0, 51, 2]\n",
      "[47, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 0, 86, 20, 0, 46, 2]\n",
      "[25, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 34, 0, 61, 2]\n",
      "[35, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 0, 138, 58, 0, 61, 2]\n",
      "[45, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 105, 648, 0, 61, 2]\n",
      "[54, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 155, 225, 0, 67, 2]\n",
      "[33, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 0, 63, 80, 0, 31, 2]\n",
      "[7, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 0, 256, 25, 0, 61, 2]\n",
      "[42, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 0, 62, 68, 0, 29, 2]\n",
      "[52, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 85, 30, 0, 61, 2]\n",
      "[45, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 0, 81, 65, 0, 61, 1]\n",
      "[36, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 141, 75, 0, 61, 2]\n",
      "[69, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 119, 136, 0, 61, 2]\n",
      "[24, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 105, 34, 0, 61, 2]\n",
      "[50, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 139, 81, 0, 62, 2]\n",
      "[61, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 0, 105, 85, 0, 61, 2]\n",
      "[54, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 0, 85, 28, 0, 61, 2]\n",
      "[56, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 90, 153, 0, 61, 2]\n",
      "[20, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 160, 118, 0, 23, 2]\n",
      "[42, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 85, 40, 0, 61, 2]\n",
      "[37, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 0, 105, 231, 0, 61, 2]\n",
      "[50, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 0, 85, 75, 0, 72, 2]\n",
      "[34, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 70, 24, 0, 100, 2]\n",
      "[28, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 105, 20, 0, 61, 2]\n",
      "[50, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 0, 155, 75, 0, 32, 2]\n",
      "[54, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 0, 85, 92, 0, 66, 2]\n",
      "[57, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 0, 82, 55, 0, 30, 2]\n",
      "[54, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 85, 30, 0, 0, 2]\n",
      "[31, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 0, 105, 101, 0, 61, 2]\n",
      "[48, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 0, 158, 278, 0, 61, 2]\n",
      "[72, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 115, 52, 0, 50, 2]\n",
      "[38, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 243, 49, 0, 90, 2]\n",
      "[25, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 181, 181, 0, 57, 2]\n",
      "[51, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 0, 105, 33, 0, 61, 2]\n",
      "[38, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 0, 130, 140, 0, 56, 2]\n",
      "[47, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 0, 166, 30, 0, 31, 2]\n",
      "[45, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 85, 44, 0, 85, 2]\n",
      "[36, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 295, 60, 0, 61, 2]\n",
      "[54, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 0, 120, 28, 0, 43, 2]\n",
      "[51, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 0, 105, 20, 0, 63, 2]\n",
      "[49, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 0, 85, 70, 0, 35, 2]\n",
      "[45, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 105, 114, 0, 61, 2]\n",
      "[31, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 75, 173, 0, 54, 2]\n",
      "[41, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 0, 65, 120, 0, 61, 2]\n",
      "[70, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 109, 528, 0, 35, 2]\n",
      "[20, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 89, 152, 0, 61, 2]\n",
      "[36, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 120, 30, 0, 61, 2]\n",
      "[46, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 0, 105, 242, 0, 50, 2]\n",
      "[44, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 126, 142, 0, 61, 2]\n",
      "[61, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 0, 75, 20, 0, 61, 2]\n",
      "[53, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 0, 81, 19, 0, 48, 2]\n",
      "[43, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 0, 100, 19, 0, 42, 2]\n"
     ]
    }
   ],
   "source": [
    "# convertir los numeros\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "Xt = [entrada.rstrip('\\n').split(',')[:-1]for entrada in lista if not entrada.startswith('@')]\n",
    "\n",
    "X = []\n",
    "\n",
    "for elemento in Xt:\n",
    "    tempArr = []\n",
    "    for ele in elemento:\n",
    "        try:\n",
    "            tempArr.append(int(ele))\n",
    "        except:\n",
    "            tempArr.append(-100)\n",
    "    X.append(tempArr)\n",
    "\n",
    "\n",
    "index = 0\n",
    "for i in range (len(X[0])):\n",
    "    arr = []\n",
    "    for fold in X:\n",
    "        if (fold[i] != -100):\n",
    "            arr.append(fold[i])\n",
    "\n",
    "    ## Mandat a calcular la moda para los datos categoricos\n",
    "    if(i in range(1, 13) or i == 18):\n",
    "        moda = mostFrequent(arr)\n",
    "        ## Substituir los -100 por la moda\n",
    "        for fold in X:\n",
    "            if (fold[i] == -100):\n",
    "                fold[i] = moda\n",
    "    elif(i in range(13,18)):\n",
    "        promedio = obtienePromedio(arr)\n",
    "        ## Substituir los -100 por el promedio\n",
    "        for fold in X:\n",
    "            if (fold[i] == -100):\n",
    "                fold[i] = promedio\n",
    "                \n",
    "for folds in X:\n",
    "    print(folds)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1.\n",
      " 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 1. 2. 2. 1. 2.\n",
      " 2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 1. 2. 2. 1. 2. 2. 2. 1. 2. 2. 1. 2. 1.\n",
      " 1. 2. 1. 1. 2. 2. 1. 2. 2. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "# para sacar y\n",
    "yt = [entrada.rstrip('\\n').split(',')[-1]for entrada in lista if not entrada.startswith('@')]\n",
    "\n",
    "y = [float(i) for i in yt]\n",
    "y = np.asarray(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second method for reading the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for opening the dataset\n",
    "def load_dataset(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset for processing:\n",
    "DATASET_PATH_CSV = \"../datasets/hepatitis.csv\"\n",
    "\n",
    "# hepatitis dataset:\n",
    "hepatitis = load_dataset(DATASET_PATH_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 155 entries, 0 to 154\n",
      "Data columns (total 20 columns):\n",
      "Age               155 non-null int64\n",
      "Sex               155 non-null int64\n",
      "Steroid           155 non-null int64\n",
      "Antivirals        155 non-null int64\n",
      "Fatigue           155 non-null int64\n",
      "Malaise           155 non-null int64\n",
      "Anorexia          155 non-null int64\n",
      "LiverBig          155 non-null int64\n",
      "LiverFirm         155 non-null int64\n",
      "SpleenPalpable    155 non-null int64\n",
      "Spiders           155 non-null int64\n",
      "Ascites           155 non-null int64\n",
      "Varices           155 non-null int64\n",
      "Bilirubin         155 non-null int64\n",
      "AlkPhosphate      155 non-null int64\n",
      "Sgot              155 non-null int64\n",
      "AlbuMin           155 non-null int64\n",
      "ProTime           155 non-null int64\n",
      "Histology         155 non-null int64\n",
      "Class             155 non-null int64\n",
      "dtypes: int64(20)\n",
      "memory usage: 24.3 KB\n"
     ]
    }
   ],
   "source": [
    "hepatitis.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain relevant information about the dataset's datatypes, this way we can know if we have to change something within the dataset for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Steroid</th>\n",
       "      <th>Antivirals</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Malaise</th>\n",
       "      <th>Anorexia</th>\n",
       "      <th>LiverBig</th>\n",
       "      <th>LiverFirm</th>\n",
       "      <th>SpleenPalpable</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Varices</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>AlkPhosphate</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>AlbuMin</th>\n",
       "      <th>ProTime</th>\n",
       "      <th>Histology</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>1.103226</td>\n",
       "      <td>1.509677</td>\n",
       "      <td>1.845161</td>\n",
       "      <td>1.348387</td>\n",
       "      <td>1.606452</td>\n",
       "      <td>1.793548</td>\n",
       "      <td>1.838710</td>\n",
       "      <td>1.612903</td>\n",
       "      <td>1.806452</td>\n",
       "      <td>1.670968</td>\n",
       "      <td>1.870968</td>\n",
       "      <td>1.883871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.264516</td>\n",
       "      <td>85.870968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.483871</td>\n",
       "      <td>1.451613</td>\n",
       "      <td>1.793548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>12.565878</td>\n",
       "      <td>0.305240</td>\n",
       "      <td>0.501527</td>\n",
       "      <td>0.362923</td>\n",
       "      <td>0.478004</td>\n",
       "      <td>0.490120</td>\n",
       "      <td>0.406070</td>\n",
       "      <td>0.368991</td>\n",
       "      <td>0.488665</td>\n",
       "      <td>0.396360</td>\n",
       "      <td>0.471385</td>\n",
       "      <td>0.336322</td>\n",
       "      <td>0.321418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.405759</td>\n",
       "      <td>88.479047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.198745</td>\n",
       "      <td>0.499266</td>\n",
       "      <td>0.406070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.500000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         Sex     Steroid  Antivirals     Fatigue     Malaise  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean    41.200000    1.103226    1.509677    1.845161    1.348387    1.606452   \n",
       "std     12.565878    0.305240    0.501527    0.362923    0.478004    0.490120   \n",
       "min      7.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%     32.000000    1.000000    1.000000    2.000000    1.000000    1.000000   \n",
       "50%     39.000000    1.000000    2.000000    2.000000    1.000000    2.000000   \n",
       "75%     50.000000    1.000000    2.000000    2.000000    2.000000    2.000000   \n",
       "max     78.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n",
       "\n",
       "         Anorexia    LiverBig   LiverFirm  SpleenPalpable     Spiders  \\\n",
       "count  155.000000  155.000000  155.000000      155.000000  155.000000   \n",
       "mean     1.793548    1.838710    1.612903        1.806452    1.670968   \n",
       "std      0.406070    0.368991    0.488665        0.396360    0.471385   \n",
       "min      1.000000    1.000000    1.000000        1.000000    1.000000   \n",
       "25%      2.000000    2.000000    1.000000        2.000000    1.000000   \n",
       "50%      2.000000    2.000000    2.000000        2.000000    2.000000   \n",
       "75%      2.000000    2.000000    2.000000        2.000000    2.000000   \n",
       "max      2.000000    2.000000    2.000000        2.000000    2.000000   \n",
       "\n",
       "          Ascites     Varices  Bilirubin  AlkPhosphate        Sgot  AlbuMin  \\\n",
       "count  155.000000  155.000000      155.0    155.000000  155.000000    155.0   \n",
       "mean     1.870968    1.883871        0.0    105.264516   85.870968      0.0   \n",
       "std      0.336322    0.321418        0.0     46.405759   88.479047      0.0   \n",
       "min      1.000000    1.000000        0.0     26.000000   14.000000      0.0   \n",
       "25%      2.000000    2.000000        0.0     78.000000   32.500000      0.0   \n",
       "50%      2.000000    2.000000        0.0    102.000000   59.000000      0.0   \n",
       "75%      2.000000    2.000000        0.0    119.500000   99.000000      0.0   \n",
       "max      2.000000    2.000000        0.0    295.000000  648.000000      0.0   \n",
       "\n",
       "          ProTime   Histology       Class  \n",
       "count  155.000000  155.000000  155.000000  \n",
       "mean    61.483871    1.451613    1.793548  \n",
       "std     17.198745    0.499266    0.406070  \n",
       "min      0.000000    1.000000    1.000000  \n",
       "25%     57.000000    1.000000    2.000000  \n",
       "50%     61.000000    1.000000    2.000000  \n",
       "75%     65.000000    2.000000    2.000000  \n",
       "max    100.000000    2.000000    2.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepatitis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Steroid</th>\n",
       "      <th>Antivirals</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Malaise</th>\n",
       "      <th>Anorexia</th>\n",
       "      <th>LiverBig</th>\n",
       "      <th>LiverFirm</th>\n",
       "      <th>SpleenPalpable</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Varices</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>AlkPhosphate</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>AlbuMin</th>\n",
       "      <th>ProTime</th>\n",
       "      <th>Histology</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Steroid  Antivirals  Fatigue  Malaise  Anorexia  LiverBig  \\\n",
       "0   30    2        1           2        2        2         2         1   \n",
       "1   50    1        1           2        1        2         2         1   \n",
       "2   78    1        2           2        1        2         2         2   \n",
       "3   31    1        2           1        2        2         2         2   \n",
       "4   34    1        2           2        2        2         2         2   \n",
       "\n",
       "   LiverFirm  SpleenPalpable  Spiders  Ascites  Varices  Bilirubin  \\\n",
       "0          2               2        2        2        2          0   \n",
       "1          2               2        2        2        2          0   \n",
       "2          2               2        2        2        2          0   \n",
       "3          2               2        2        2        2          0   \n",
       "4          2               2        2        2        2          0   \n",
       "\n",
       "   AlkPhosphate  Sgot  AlbuMin  ProTime  Histology  Class  \n",
       "0            85    18        0       61          1      2  \n",
       "1           135    42        0       61          1      2  \n",
       "2            96    32        0       61          1      2  \n",
       "3            46    52        0       80          1      2  \n",
       "4           105   200        0       61          1      2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see only the first entires in the dataset:\n",
    "hepatitis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Steroid</th>\n",
       "      <th>Antivirals</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Malaise</th>\n",
       "      <th>Anorexia</th>\n",
       "      <th>LiverBig</th>\n",
       "      <th>LiverFirm</th>\n",
       "      <th>SpleenPalpable</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Varices</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>AlkPhosphate</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>AlbuMin</th>\n",
       "      <th>ProTime</th>\n",
       "      <th>Histology</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  Steroid  Antivirals  Fatigue  Malaise  Anorexia  LiverBig  \\\n",
       "150   46    1        2           2        1        1         1         2   \n",
       "151   44    1        2           2        1        2         2         2   \n",
       "152   61    1        1           2        1        1         2         1   \n",
       "153   53    2        1           2        1        2         2         2   \n",
       "154   43    1        2           2        1        2         2         2   \n",
       "\n",
       "     LiverFirm  SpleenPalpable  Spiders  Ascites  Varices  Bilirubin  \\\n",
       "150          2               2        1        1        1          0   \n",
       "151          1               2        2        2        2          0   \n",
       "152          1               2        1        2        2          0   \n",
       "153          2               1        1        2        1          0   \n",
       "154          2               1        1        1        2          0   \n",
       "\n",
       "     AlkPhosphate  Sgot  AlbuMin  ProTime  Histology  Class  \n",
       "150           105   242        0       50          2      1  \n",
       "151           126   142        0       61          2      2  \n",
       "152            75    20        0       61          2      2  \n",
       "153            81    19        0       48          2      2  \n",
       "154           100    19        0       42          2      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepatitis.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets make a correlation matrix:\n",
    "corr_matrix = hepatitis.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corr_matrix, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Steroid</th>\n",
       "      <th>Antivirals</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Malaise</th>\n",
       "      <th>Anorexia</th>\n",
       "      <th>LiverBig</th>\n",
       "      <th>LiverFirm</th>\n",
       "      <th>SpleenPalpable</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Varices</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>AlkPhosphate</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>AlbuMin</th>\n",
       "      <th>ProTime</th>\n",
       "      <th>Histology</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>-0.090466</td>\n",
       "      <td>-0.013100</td>\n",
       "      <td>-0.278701</td>\n",
       "      <td>-0.117876</td>\n",
       "      <td>0.088317</td>\n",
       "      <td>-0.089629</td>\n",
       "      <td>-0.092001</td>\n",
       "      <td>-0.061277</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>-0.055314</td>\n",
       "      <td>-0.039229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.081030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.152845</td>\n",
       "      <td>0.170780</td>\n",
       "      <td>-0.219647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sex</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048985</td>\n",
       "      <td>-0.089249</td>\n",
       "      <td>-0.070059</td>\n",
       "      <td>-0.030523</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>-0.081830</td>\n",
       "      <td>-0.078642</td>\n",
       "      <td>-0.048478</td>\n",
       "      <td>-0.033192</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>0.056792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>-0.017536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007102</td>\n",
       "      <td>-0.137450</td>\n",
       "      <td>0.173051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Steroid</td>\n",
       "      <td>-0.090466</td>\n",
       "      <td>-0.048985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043961</td>\n",
       "      <td>0.175451</td>\n",
       "      <td>0.240139</td>\n",
       "      <td>0.073644</td>\n",
       "      <td>0.201478</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.074816</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>-0.031046</td>\n",
       "      <td>-0.073548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044333</td>\n",
       "      <td>-0.044018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084145</td>\n",
       "      <td>-0.095367</td>\n",
       "      <td>0.137413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Antivirals</td>\n",
       "      <td>-0.013100</td>\n",
       "      <td>-0.089249</td>\n",
       "      <td>0.043961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061339</td>\n",
       "      <td>-0.016251</td>\n",
       "      <td>-0.042072</td>\n",
       "      <td>0.054746</td>\n",
       "      <td>0.099213</td>\n",
       "      <td>-0.164548</td>\n",
       "      <td>-0.147909</td>\n",
       "      <td>-0.164747</td>\n",
       "      <td>-0.155148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197156</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>0.209242</td>\n",
       "      <td>-0.130196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fatigue</td>\n",
       "      <td>-0.278701</td>\n",
       "      <td>-0.070059</td>\n",
       "      <td>0.175451</td>\n",
       "      <td>-0.061339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.589030</td>\n",
       "      <td>0.372957</td>\n",
       "      <td>0.099759</td>\n",
       "      <td>0.247505</td>\n",
       "      <td>0.186846</td>\n",
       "      <td>0.367948</td>\n",
       "      <td>0.281439</td>\n",
       "      <td>0.180511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.148793</td>\n",
       "      <td>-0.199754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.206842</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>0.306049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Malaise</td>\n",
       "      <td>-0.117876</td>\n",
       "      <td>-0.030523</td>\n",
       "      <td>0.240139</td>\n",
       "      <td>-0.016251</td>\n",
       "      <td>0.589030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600545</td>\n",
       "      <td>0.041697</td>\n",
       "      <td>0.091832</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.307173</td>\n",
       "      <td>0.320228</td>\n",
       "      <td>0.161422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.194957</td>\n",
       "      <td>-0.202878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199144</td>\n",
       "      <td>-0.144667</td>\n",
       "      <td>0.339530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Anorexia</td>\n",
       "      <td>0.088317</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>0.073644</td>\n",
       "      <td>-0.042072</td>\n",
       "      <td>0.372957</td>\n",
       "      <td>0.600545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079685</td>\n",
       "      <td>0.052781</td>\n",
       "      <td>0.032536</td>\n",
       "      <td>0.287366</td>\n",
       "      <td>0.184053</td>\n",
       "      <td>0.163378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.153184</td>\n",
       "      <td>-0.234796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046939</td>\n",
       "      <td>-0.081623</td>\n",
       "      <td>0.133638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LiverBig</td>\n",
       "      <td>-0.089629</td>\n",
       "      <td>-0.081830</td>\n",
       "      <td>0.201478</td>\n",
       "      <td>0.054746</td>\n",
       "      <td>0.099759</td>\n",
       "      <td>0.041697</td>\n",
       "      <td>0.079685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479779</td>\n",
       "      <td>0.095959</td>\n",
       "      <td>0.215566</td>\n",
       "      <td>-0.116465</td>\n",
       "      <td>-0.049453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.124531</td>\n",
       "      <td>0.050275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.060262</td>\n",
       "      <td>-0.093665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LiverFirm</td>\n",
       "      <td>-0.092001</td>\n",
       "      <td>-0.078642</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.099213</td>\n",
       "      <td>0.247505</td>\n",
       "      <td>0.091832</td>\n",
       "      <td>0.052781</td>\n",
       "      <td>0.479779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180607</td>\n",
       "      <td>0.345553</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>0.208047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.324471</td>\n",
       "      <td>-0.093076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022431</td>\n",
       "      <td>-0.157118</td>\n",
       "      <td>0.020057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SpleenPalpable</td>\n",
       "      <td>-0.061277</td>\n",
       "      <td>-0.048478</td>\n",
       "      <td>0.074816</td>\n",
       "      <td>-0.164548</td>\n",
       "      <td>0.186846</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.032536</td>\n",
       "      <td>0.095959</td>\n",
       "      <td>0.180607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.282523</td>\n",
       "      <td>0.103709</td>\n",
       "      <td>0.230190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.257385</td>\n",
       "      <td>0.017985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114799</td>\n",
       "      <td>-0.211702</td>\n",
       "      <td>0.234261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spiders</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>-0.033192</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>-0.147909</td>\n",
       "      <td>0.367948</td>\n",
       "      <td>0.307173</td>\n",
       "      <td>0.287366</td>\n",
       "      <td>0.215566</td>\n",
       "      <td>0.345553</td>\n",
       "      <td>0.282523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303888</td>\n",
       "      <td>0.389041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.263751</td>\n",
       "      <td>-0.078092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218402</td>\n",
       "      <td>-0.357796</td>\n",
       "      <td>0.389137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ascites</td>\n",
       "      <td>-0.055314</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>-0.031046</td>\n",
       "      <td>-0.164747</td>\n",
       "      <td>0.281439</td>\n",
       "      <td>0.320228</td>\n",
       "      <td>0.184053</td>\n",
       "      <td>-0.116465</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>0.103709</td>\n",
       "      <td>0.303888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.341039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.128440</td>\n",
       "      <td>0.034569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280289</td>\n",
       "      <td>-0.346796</td>\n",
       "      <td>0.469334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Varices</td>\n",
       "      <td>-0.039229</td>\n",
       "      <td>0.056792</td>\n",
       "      <td>-0.073548</td>\n",
       "      <td>-0.155148</td>\n",
       "      <td>0.180511</td>\n",
       "      <td>0.161422</td>\n",
       "      <td>0.163378</td>\n",
       "      <td>-0.049453</td>\n",
       "      <td>0.208047</td>\n",
       "      <td>0.230190</td>\n",
       "      <td>0.389041</td>\n",
       "      <td>0.341039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.276115</td>\n",
       "      <td>-0.012404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.235766</td>\n",
       "      <td>-0.358961</td>\n",
       "      <td>0.362385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bilirubin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AlkPhosphate</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>-0.044333</td>\n",
       "      <td>0.197156</td>\n",
       "      <td>-0.148793</td>\n",
       "      <td>-0.194957</td>\n",
       "      <td>-0.153184</td>\n",
       "      <td>-0.124531</td>\n",
       "      <td>-0.324471</td>\n",
       "      <td>-0.257385</td>\n",
       "      <td>-0.263751</td>\n",
       "      <td>-0.128440</td>\n",
       "      <td>-0.276115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.190649</td>\n",
       "      <td>0.255180</td>\n",
       "      <td>-0.140778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sgot</td>\n",
       "      <td>0.081030</td>\n",
       "      <td>-0.017536</td>\n",
       "      <td>-0.044018</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>-0.199754</td>\n",
       "      <td>-0.202878</td>\n",
       "      <td>-0.234796</td>\n",
       "      <td>0.050275</td>\n",
       "      <td>-0.093076</td>\n",
       "      <td>0.017985</td>\n",
       "      <td>-0.078092</td>\n",
       "      <td>0.034569</td>\n",
       "      <td>-0.012404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137571</td>\n",
       "      <td>0.129656</td>\n",
       "      <td>-0.075389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AlbuMin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ProTime</td>\n",
       "      <td>-0.152845</td>\n",
       "      <td>-0.007102</td>\n",
       "      <td>0.084145</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>0.206842</td>\n",
       "      <td>0.199144</td>\n",
       "      <td>0.046939</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>0.022431</td>\n",
       "      <td>0.114799</td>\n",
       "      <td>0.218402</td>\n",
       "      <td>0.280289</td>\n",
       "      <td>0.235766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.190649</td>\n",
       "      <td>-0.137571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.235088</td>\n",
       "      <td>0.307278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Histology</td>\n",
       "      <td>0.170780</td>\n",
       "      <td>-0.137450</td>\n",
       "      <td>-0.095367</td>\n",
       "      <td>0.209242</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>-0.144667</td>\n",
       "      <td>-0.081623</td>\n",
       "      <td>-0.060262</td>\n",
       "      <td>-0.157118</td>\n",
       "      <td>-0.211702</td>\n",
       "      <td>-0.357796</td>\n",
       "      <td>-0.346796</td>\n",
       "      <td>-0.358961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255180</td>\n",
       "      <td>0.129656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.235088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.337856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Class</td>\n",
       "      <td>-0.219647</td>\n",
       "      <td>0.173051</td>\n",
       "      <td>0.137413</td>\n",
       "      <td>-0.130196</td>\n",
       "      <td>0.306049</td>\n",
       "      <td>0.339530</td>\n",
       "      <td>0.133638</td>\n",
       "      <td>-0.093665</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.234261</td>\n",
       "      <td>0.389137</td>\n",
       "      <td>0.469334</td>\n",
       "      <td>0.362385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.140778</td>\n",
       "      <td>-0.075389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307278</td>\n",
       "      <td>-0.337856</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Age       Sex   Steroid  Antivirals   Fatigue   Malaise  \\\n",
       "Age             1.000000  0.008126 -0.090466   -0.013100 -0.278701 -0.117876   \n",
       "Sex             0.008126  1.000000 -0.048985   -0.089249 -0.070059 -0.030523   \n",
       "Steroid        -0.090466 -0.048985  1.000000    0.043961  0.175451  0.240139   \n",
       "Antivirals     -0.013100 -0.089249  0.043961    1.000000 -0.061339 -0.016251   \n",
       "Fatigue        -0.278701 -0.070059  0.175451   -0.061339  1.000000  0.589030   \n",
       "Malaise        -0.117876 -0.030523  0.240139   -0.016251  0.589030  1.000000   \n",
       "Anorexia        0.088317  0.015886  0.073644   -0.042072  0.372957  0.600545   \n",
       "LiverBig       -0.089629 -0.081830  0.201478    0.054746  0.099759  0.041697   \n",
       "LiverFirm      -0.092001 -0.078642  0.068376    0.099213  0.247505  0.091832   \n",
       "SpleenPalpable -0.061277 -0.048478  0.074816   -0.164548  0.186846  0.006470   \n",
       "Spiders        -0.156545 -0.033192  0.027290   -0.147909  0.367948  0.307173   \n",
       "Ascites        -0.055314  0.130587 -0.031046   -0.164747  0.281439  0.320228   \n",
       "Varices        -0.039229  0.056792 -0.073548   -0.155148  0.180511  0.161422   \n",
       "Bilirubin            NaN       NaN       NaN         NaN       NaN       NaN   \n",
       "AlkPhosphate    0.008238  0.073700 -0.044333    0.197156 -0.148793 -0.194957   \n",
       "Sgot            0.081030 -0.017536 -0.044018    0.107764 -0.199754 -0.202878   \n",
       "AlbuMin              NaN       NaN       NaN         NaN       NaN       NaN   \n",
       "ProTime        -0.152845 -0.007102  0.084145   -0.034733  0.206842  0.199144   \n",
       "Histology       0.170780 -0.137450 -0.095367    0.209242 -0.146579 -0.144667   \n",
       "Class          -0.219647  0.173051  0.137413   -0.130196  0.306049  0.339530   \n",
       "\n",
       "                Anorexia  LiverBig  LiverFirm  SpleenPalpable   Spiders  \\\n",
       "Age             0.088317 -0.089629  -0.092001       -0.061277 -0.156545   \n",
       "Sex             0.015886 -0.081830  -0.078642       -0.048478 -0.033192   \n",
       "Steroid         0.073644  0.201478   0.068376        0.074816  0.027290   \n",
       "Antivirals     -0.042072  0.054746   0.099213       -0.164548 -0.147909   \n",
       "Fatigue         0.372957  0.099759   0.247505        0.186846  0.367948   \n",
       "Malaise         0.600545  0.041697   0.091832        0.006470  0.307173   \n",
       "Anorexia        1.000000  0.079685   0.052781        0.032536  0.287366   \n",
       "LiverBig        0.079685  1.000000   0.479779        0.095959  0.215566   \n",
       "LiverFirm       0.052781  0.479779   1.000000        0.180607  0.345553   \n",
       "SpleenPalpable  0.032536  0.095959   0.180607        1.000000  0.282523   \n",
       "Spiders         0.287366  0.215566   0.345553        0.282523  1.000000   \n",
       "Ascites         0.184053 -0.116465   0.010196        0.103709  0.303888   \n",
       "Varices         0.163378 -0.049453   0.208047        0.230190  0.389041   \n",
       "Bilirubin            NaN       NaN        NaN             NaN       NaN   \n",
       "AlkPhosphate   -0.153184 -0.124531  -0.324471       -0.257385 -0.263751   \n",
       "Sgot           -0.234796  0.050275  -0.093076        0.017985 -0.078092   \n",
       "AlbuMin              NaN       NaN        NaN             NaN       NaN   \n",
       "ProTime         0.046939 -0.070503   0.022431        0.114799  0.218402   \n",
       "Histology      -0.081623 -0.060262  -0.157118       -0.211702 -0.357796   \n",
       "Class           0.133638 -0.093665   0.020057        0.234261  0.389137   \n",
       "\n",
       "                 Ascites   Varices  Bilirubin  AlkPhosphate      Sgot  \\\n",
       "Age            -0.055314 -0.039229        NaN      0.008238  0.081030   \n",
       "Sex             0.130587  0.056792        NaN      0.073700 -0.017536   \n",
       "Steroid        -0.031046 -0.073548        NaN     -0.044333 -0.044018   \n",
       "Antivirals     -0.164747 -0.155148        NaN      0.197156  0.107764   \n",
       "Fatigue         0.281439  0.180511        NaN     -0.148793 -0.199754   \n",
       "Malaise         0.320228  0.161422        NaN     -0.194957 -0.202878   \n",
       "Anorexia        0.184053  0.163378        NaN     -0.153184 -0.234796   \n",
       "LiverBig       -0.116465 -0.049453        NaN     -0.124531  0.050275   \n",
       "LiverFirm       0.010196  0.208047        NaN     -0.324471 -0.093076   \n",
       "SpleenPalpable  0.103709  0.230190        NaN     -0.257385  0.017985   \n",
       "Spiders         0.303888  0.389041        NaN     -0.263751 -0.078092   \n",
       "Ascites         1.000000  0.341039        NaN     -0.128440  0.034569   \n",
       "Varices         0.341039  1.000000        NaN     -0.276115 -0.012404   \n",
       "Bilirubin            NaN       NaN        NaN           NaN       NaN   \n",
       "AlkPhosphate   -0.128440 -0.276115        NaN      1.000000  0.193817   \n",
       "Sgot            0.034569 -0.012404        NaN      0.193817  1.000000   \n",
       "AlbuMin              NaN       NaN        NaN           NaN       NaN   \n",
       "ProTime         0.280289  0.235766        NaN     -0.190649 -0.137571   \n",
       "Histology      -0.346796 -0.358961        NaN      0.255180  0.129656   \n",
       "Class           0.469334  0.362385        NaN     -0.140778 -0.075389   \n",
       "\n",
       "                AlbuMin   ProTime  Histology     Class  \n",
       "Age                 NaN -0.152845   0.170780 -0.219647  \n",
       "Sex                 NaN -0.007102  -0.137450  0.173051  \n",
       "Steroid             NaN  0.084145  -0.095367  0.137413  \n",
       "Antivirals          NaN -0.034733   0.209242 -0.130196  \n",
       "Fatigue             NaN  0.206842  -0.146579  0.306049  \n",
       "Malaise             NaN  0.199144  -0.144667  0.339530  \n",
       "Anorexia            NaN  0.046939  -0.081623  0.133638  \n",
       "LiverBig            NaN -0.070503  -0.060262 -0.093665  \n",
       "LiverFirm           NaN  0.022431  -0.157118  0.020057  \n",
       "SpleenPalpable      NaN  0.114799  -0.211702  0.234261  \n",
       "Spiders             NaN  0.218402  -0.357796  0.389137  \n",
       "Ascites             NaN  0.280289  -0.346796  0.469334  \n",
       "Varices             NaN  0.235766  -0.358961  0.362385  \n",
       "Bilirubin           NaN       NaN        NaN       NaN  \n",
       "AlkPhosphate        NaN -0.190649   0.255180 -0.140778  \n",
       "Sgot                NaN -0.137571   0.129656 -0.075389  \n",
       "AlbuMin             NaN       NaN        NaN       NaN  \n",
       "ProTime             NaN  1.000000  -0.235088  0.307278  \n",
       "Histology           NaN -0.235088   1.000000 -0.337856  \n",
       "Class               NaN  0.307278  -0.337856  1.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation matrix to see what variables relate the most\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a generar los conjuntos de prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('SVM',\n",
       "                 SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='poly', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Crear maquina de soporte vectorial\n",
    "poly_kernel_svm_clf=Pipeline([\n",
    "    (\"scaler\", StandardScaler()), \n",
    "    (\"SVM\", SVC(kernel=\"poly\", degree=3, C=5))])\n",
    "poly_kernel_svm_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para predecir los test con poly_kernel_svm_clf\n",
    "y_pred1=poly_kernel_svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best configuration for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('SVM',\n",
      "                 SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3, gamma=0.1,\n",
      "                     kernel='poly', max_iter=-1, probability=False,\n",
      "                     random_state=None, shrinking=True, tol=0.001,\n",
      "                     verbose=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "  {'C': [1,10], 'kernel': ['linear', 'poly']},\n",
    "  {'C': [1, 10, 20], 'gamma': [0.001, 0.0001], 'kernel': ['rbf', 'poly']},\n",
    " ]\n",
    "parameteres = {'SVM__C':[0.001,0.1,10,100,10e5], 'SVM__gamma':[0.1,0.01]}\n",
    "bestClfSVM = GridSearchCV(poly_kernel_svm_clf, param_grid = parameteres, cv = 5)\n",
    "\n",
    "bestClfSVM.fit(X_train,y_train)\n",
    "print(bestClfSVM.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para predecir los test con bestClfSVM\n",
    "y_pred2=bestClfSVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for SVM with degree 3 is:0.7435897435897436\n",
      "The Accuracy for SVM with GridSearch is:0.717948717948718\n"
     ]
    }
   ],
   "source": [
    "###### Vamos a generar los resultados\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Maquina de soporte vectorial con grado 3\n",
    "result1SVM=accuracy_score(y_test,y_pred1)\n",
    "print(\"The Accuracy for SVM with degree 3 is:\" + str(result1SVM))\n",
    "\n",
    "\n",
    "result2SVM=accuracy_score(y_test,y_pred2)\n",
    "print(\"The Accuracy for SVM with GridSearch is:\" + str(result2SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Multilayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(6,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_perceptron = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(6,), random_state=1,activation='relu')\n",
    "clf_perceptron.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para predecir los test con poly_kernel_svm_clf\n",
    "y_pred1_perceptron = clf_perceptron.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best configuration for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.005, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:   17.1s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "          'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "          'learning_rate_init': [.1,.05,.01,.005,.001]}\n",
    "clf_grid_search_perceptron = GridSearchCV(\n",
    "    MLPClassifier(random_state=42), params, verbose=1, cv=3)\n",
    "\n",
    "clf_grid_search_perceptron.fit(X_train, y_train)\n",
    "print(clf_grid_search_perceptron.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy score for the best configuration calculated with grid_search_cv\n",
    "y_pred2_perceptron = clf_grid_search_perceptron.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for MLP: 0.7692307692307693\n",
      "The Accuracy for MLP with GridSearch is: 0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "###### Vamos a generar los resultados\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "result1MLP=accuracy_score(y_test, y_pred1_perceptron)\n",
    "print(\"The Accuracy for MLP: \" + str(result1MLP))\n",
    "\n",
    "\n",
    "result2MLP=accuracy_score(y_test, y_pred2_perceptron)\n",
    "print(\"The Accuracy for MLP with GridSearch is: \" + str(result2MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para predecir los test con sgd_clf\n",
    "y_pred1_SGD = sgd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best configuration for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=10, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
      "              random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          \"penalty\": [\"none\", \"l1\", \"l2\"]}\n",
    "\n",
    "clf_grid_search_sgd = GridSearchCV(sgd_clf, params)\n",
    "\n",
    "clf_grid_search_sgd.fit(X_train, y_train)\n",
    "print(clf_grid_search_sgd.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy score for the best configuration calculated with clf_grid_search_sgd\n",
    "y_pred2_SGD = clf_grid_search_sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for SGD: 0.7692307692307693\n",
      "The Accuracy for SGD with GridSearch is: 0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "###### Vamos a generar los resultados\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "result1SGD=accuracy_score(y_test, y_pred1_SGD)\n",
    "print(\"The Accuracy for SGD: \" + str(result1MLP))\n",
    "\n",
    "\n",
    "result2SGD=accuracy_score(y_test, y_pred2_SGD)\n",
    "print(\"The Accuracy for SGD with GridSearch is: \" + str(result2MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_clf = KMeans(n_clusters=3, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=42, copy_x=True, n_jobs=None, algorithm='auto')\n",
    "kmeans_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para predecir los test con kmeans_clf\n",
    "y_pred1_KM = kmeans_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best configuration for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "       n_clusters=9, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "       random_state=42, tol=0.0001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    1.2s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"n_clusters\": range(2, 10)}\n",
    "\n",
    "clf_grid_search_KM = GridSearchCV( \n",
    "    KMeans(random_state=42), params, verbose=1, cv=3 ) \n",
    "\n",
    "clf_grid_search_KM.fit(X_train, y_train)\n",
    "\n",
    "print(clf_grid_search_KM.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy score for the best configuration calculated with clf_grid_search_KM\n",
    "y_pred2_KM = clf_grid_search_KM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for KMeans: 0.7692307692307693\n",
      "The Accuracy for Kmeans with GridSearch is: 0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "###### Vamos a generar los resultados\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "result1KM=accuracy_score(y_test, y_pred1_KM)\n",
    "print(\"The Accuracy for KMeans: \" + str(result1MLP))\n",
    "\n",
    "\n",
    "result1KM=accuracy_score(y_test, y_pred2_KM)\n",
    "print(\"The Accuracy for Kmeans with GridSearch is: \" + str(result2MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
